---
permalink: /experience/
title: Experience
---

- **Interned at Adobe Research (May - July 2024)**  
  <details>
    <summary>Project: On Device Generative AI</summary>
    <ul>
      <li>Worked on optimizing latency and compute to enable LLM inferencing on edge devices in blackbox and whitebox settings.</li>
      <li>Conducted an extensive literature survey on state-of-the-art techniques including prompt compression, quantization, early exit, knowledge distillation, layer skipping, and lightweight models, focusing on optimization with minimal quality degradation.</li>
      <li>Devised a heuristic-based prompt compression technique in the blackbox setting, achieving 50% improvement in time to first token and 70% in compression latency compared to LLM Lingua 2 with less than 5% quality degradation.</li>
    </ul>
  </details>

- **Incoming Software Engineer at Microsoft**