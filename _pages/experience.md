---
permalink: /experience/
title: “Experience”
---

**Interned at Adobe Research (May - July 2024)**  
  <details>
    <summary>Project: On Device Generative AI</summary>
    Worked on optimising latency and compute to enable LLM inferencing on edge devices in blackbox and whitebox settings. Did an extensive literature survey on state-of-the-art techniques including prompt compression, quantization, early exit, knowledge distillation, layer skipping, and lightweight models, focusing on optimization with least quality degradation. Devised heuristics based prompt compression technique in the blackbox setting, achieved 50% improvement in time to first token and 70% in compression latency with respect to LLM Lingua 2 with less than 5% degradation in quality.
  </details>

**Incoming Software Engineer at Microsoft**